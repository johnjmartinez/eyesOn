using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.IO;
using System.Threading;
using System.Threading.Tasks;
using System.Drawing;

using Android;
using Android.App;
using Android.Content;
using Android.Content.PM;
using Android.OS;
using Android.Util;
using Android.Views;
//using Android.Widget;
using Android.Hardware.Camera2;
using Android.Graphics;
using Android.Hardware.Camera2.Params;
using Android.Media;
using Android.Runtime;
using Android.Preferences;

using Java.IO;
using Java.Lang;
using Java.Nio;
using Java.Util;
using Java.Util.Concurrent;

using Boolean = Java.Lang.Boolean;
using Math = Java.Lang.Math;
using Orientation = Android.Content.Res.Orientation;

using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.Util;

using EyesOn.UI.Droid.Utilities;
using EyesOn.UI.Droid.ColorBlobDetection;
using EyesOn.UI.Droid.TakePhoto.Listeners;

namespace EyesOn.UI.Droid.TakePhoto
{
    [Activity(Label = "Take Photo 3", ScreenOrientation = Android.Content.PM.ScreenOrientation.Portrait)]
    public class TakePhotoActivityJJM : Activity //, ISurfaceHolderCallback
    {
        //float L, T, R, B;
        //float screenX;
        //float screenY;
        string eyeXml;
        string faceXml;

        CascadeClassifier face = null;
        CascadeClassifier eye = null;

        //Bitmap imageFromCam;

        /************************ NEW ***************************/

        private static readonly SparseIntArray ORIENTATIONS = new SparseIntArray();
        public static readonly int REQUEST_CAMERA_PERMISSION = 1;
        //private static readonly string FRAGMENT_DIALOG = "dialog";

        // Tag for {@link Log}.
        private static readonly string TAG = "TakePhoto3";

        private readonly object _lock = new object();
        private volatile bool isBusy = false;

        // Camera states
        public const int STATE_PREVIEW = 0;                 //Showing camera preview.
        public const int STATE_WAITING_LOCK = 1;            //Waiting for focus to be locked.
        public const int STATE_WAITING_PRECAPTURE = 2;      //Waiting for exposure to be precapture state.
        public const int STATE_WAITING_NON_PRECAPTURE = 3;  //Waiting for exposure state to be something other than precapture.
        public const int STATE_PICTURE_TAKEN = 4;           //Picture was taken.

        public int mState = STATE_PREVIEW; // current state of camera state for taking pictures.

        private static readonly int MAX_PREVIEW_WIDTH = 2560;  // Max preview width that is guaranteed by Camera2 API
        private static readonly int MAX_PREVIEW_HEIGHT = 1440; // Max preview height that is guaranteed by Camera2 API

        // size of camera preview
        private Android.Util.Size mPreviewSize;

        // TextureView.ISurfaceTextureListener handles several lifecycle events on TextureView
        private Camera2BasicSurfaceTextureListener mSurfaceTextureListener;

        private AutoFitTextureView mTextureView;    // An AutoFitTextureView for camera preview
        private SurfaceView mTransparentView;       //for drawing


        // reference to opened CameraDevice
        public CameraDevice mCameraDevice;

        // ID of current {@link CameraDevice}.
        private string mCameraId;

        // Whether current camera device supports Flash or not.
        private bool mFlashSupported;

        // Orientation of camera sensor
        private int mSensorOrientation;

        // CameraDevice.StateListener is called when CameraDevice changes its state
        private CameraStateListener mStateCallback;

        private HandlerThread mBackgroundThread; // additional thread for running tasks that shouldn't block UI.

        public CameraCaptureSession mCaptureSession; //for camera preview.
        public CaptureRequest mPreviewRequest; //generated by {@link #mPreviewRequestBuilder}
        public CaptureRequest.Builder mPreviewRequestBuilder; //for camera preview
        public Handler mBackgroundHandler; // for running tasks in background.
        private ImageReader mImageReader;  // handles still image capture.

        // Callback object for {@link ImageReader}.
        //"onImageAvailable" will be called when still image is ready to be saved.
        private ImageAvailableListener mOnImageAvailableListener;

        // {@link CameraCaptureSession.CaptureCallback} that handles events related to JPEG capture.
        public CameraCaptureListener mCaptureCallback;

        // {@link Semaphore} to prevent app from exiting before closing camera.
        public Java.Util.Concurrent.Semaphore mCameraOpenCloseLock = new Java.Util.Concurrent.Semaphore(1);

        public TakePhotoActivityJJM() { }

        protected override void OnCreate(Bundle savedInstanceState)
        {
            base.OnCreate(savedInstanceState);

            //opencv preferences
            AppPreference appPreference = new AppPreference();
            CvInvoke.UseOpenCL = appPreference.UseOpenCL;
            string oclDeviceName = appPreference.OpenClDeviceName;
            if (!string.IsNullOrEmpty(oclDeviceName))
                CvInvoke.OclSetDefaultDevice(oclDeviceName);

            ISharedPreferences preference = PreferenceManager.GetDefaultSharedPreferences(ApplicationContext);
            string appVersion = PackageManager.GetPackageInfo(PackageName, Android.Content.PM.PackageInfoFlags.Activities).VersionName;
            if (!preference.Contains("cascade-data-version") || !preference.GetString("cascade-data-version", null).Equals(appVersion)
               || !(preference.Contains("cascade-eye-data-path") || preference.Contains("cascade-face-data-path")))
            {
                AndroidFileAsset.OverwriteMethod overwriteMethod = AndroidFileAsset.OverwriteMethod.AlwaysOverwrite;

                FileInfo eyeFile = AndroidFileAsset.WritePermanantFileAsset(this, "haarcascade_eye.xml", "cascade", overwriteMethod);
                FileInfo faceFile = AndroidFileAsset.WritePermanantFileAsset(this, "haarcascade_frontalface_alt_tree.xml", "cascade", overwriteMethod);

                //save tesseract data path
                ISharedPreferencesEditor editor = preference.Edit();
                editor.PutString("cascade-data-version", appVersion);
                editor.PutString("cascade-eye-data-path", eyeFile.FullName);
                editor.PutString("cascade-face-data-path", faceFile.FullName);
                editor.Commit();
            }

            eyeXml = preference.GetString("cascade-eye-data-path", null);
            faceXml = preference.GetString("cascade-face-data-path", null);

            face = new CascadeClassifier(faceXml);
            eye = new CascadeClassifier(eyeXml);

            // Hide window title and go fullscreen.
            RequestWindowFeature(WindowFeatures.NoTitle);
            Window.AddFlags(WindowManagerFlags.Fullscreen);

            SetContentView(Resource.Layout.take_photo_surface_view);
            mTextureView = (AutoFitTextureView)FindViewById(Resource.Id.CameraView);
          
            var manager = GetSystemService(Context.WindowService).JavaCast<IWindowManager>();
            var size = new Android.Graphics.Point();
            manager.DefaultDisplay.GetSize(size);

            mStateCallback = new CameraStateListener() { owner = this };
            mSurfaceTextureListener = new Camera2BasicSurfaceTextureListener(this);
            mOnImageAvailableListener = new ImageAvailableListener() { Owner = this };

            // fill ORIENTATIONS list
            ORIENTATIONS.Append((int)SurfaceOrientation.Rotation0, 90);
            ORIENTATIONS.Append((int)SurfaceOrientation.Rotation90, 0);
            ORIENTATIONS.Append((int)SurfaceOrientation.Rotation180, 270);
            ORIENTATIONS.Append((int)SurfaceOrientation.Rotation270, 180);
        }

        protected override void OnResume()
        {

            base.OnResume();
            StartBackgroundThread();

            // When screen is turned off and turned back on, SurfaceTexture is already
            // available, and "onSurfaceTextureAvailable" will not be called. In that case, can open
            // camera and start preview from here (otherwise, wait until surface is ready in
            // SurfaceTextureListener).
            if (mTextureView.IsAvailable)
                OpenCamera(mTextureView.Width, mTextureView.Height);
            else
                mTextureView.SurfaceTextureListener = mSurfaceTextureListener;
        }

        protected override void OnPause()
        {
            CloseCamera();
            StopBackgroundThread();
            base.OnPause();
        }

        // CALLED BY PREVIEW FRAME 
        private void DrawFocusRect(Canvas canvas, FaceEyes FE, Android.Graphics.Color color) 
        {
            //lock
            //var canvas = holder.LockCanvas();

            //no pointer to canvas?
            if (canvas == null) return;

            Log.Error(TAG, "\t\t -----DrawFocusRect");

            //clear out
            //canvas.DrawColor(Android.Graphics.Color.Transparent, Android.Graphics.PorterDuff.Mode.Clear);

            //border's properties
            var paint = new Android.Graphics.Paint();
            paint.SetStyle(Android.Graphics.Paint.Style.Stroke);
            paint.Color = color;
            paint.StrokeWidth = 3;

            Rectangle e0 = FE.Eyes[0];
            Rectangle e1 = FE.Eyes[1];
            Rectangle f0 = FE.Faces[0];

            canvas.DrawRect(new Rect(e0.Left, e0.Top, e0.Right, e0.Bottom), paint);
            canvas.DrawRect(new Rect(e1.Left, e1.Top, e1.Right, e1.Bottom), paint);
            canvas.DrawRect(new Rect(f0.Left, f0.Top, f0.Right, f0.Bottom), paint);

            //unlock
            //holder.UnlockCanvasAndPost(canvas);
        }

        //CALLED BY ImageAvailableListener
        //public void PreviewFrame(Mat image)
        public void PreviewFrame(SurfaceTexture surfText)
        { 
            Surface surface = new Surface(surfText);
            Image image = mImageReader.AcquireNextImage();
            //Rect dirty = new Rect(1,1,mImageReader.Height-1,mImageReader.Width-1);
            Rect dirty = new Rect(1, 1, image.Width-1, image.Height-1);
            Canvas canvas = surface.LockCanvas(dirty);
            //Image image = reader.AcquireLatestImage();
            Mat img = null;
            FaceEyes results = null;

            lock (_lock)
            {
                if (!isBusy)
                {
                    isBusy = true;
                    var mythread = Task.Factory.StartNew(() =>
                    {
                        try
                        {
                            if (image != null)
                            {
                                ByteBuffer buffer = image.GetPlanes()[0].Buffer;
                                byte[] bytes = new byte[buffer.Remaining()];
                                buffer.Get(bytes);

                                img = new Mat(image.Height, image.Width, Emgu.CV.CvEnum.DepthType.Cv8U, 3);
                                CvInvoke.Imdecode(bytes, Emgu.CV.CvEnum.ImreadModes.Unchanged, img);

                                image.Close();
                            }
                            else
                                Log.Error(TAG, "\t\t------ PreviewFrame image == null");


                            if (img != null)
                                 results = Detect(img);
                            else
                                Log.Error(TAG, "\t\t------ PreviewFrame Mat img == null");

                            if (results.Count > 0)
                            {
                                //   int stopmehere = 1;
                                RunOnUiThread(() =>
                                {
                                    //code to update UI
                                    Log.Error(TAG, "\t\t------PreviewFrame");
                                    //Surface surface = new Surface(mTextureView.SurfaceTexture);
                                    //Canvas cv = mTextureView.LockCanvas();
                                    DrawFocusRect(canvas, results, Android.Graphics.Color.Yellow);
                                });
                            }
                        }
                        catch (System.Exception ex)
                        {
                            Log.Error(TAG+"\t\tImageAvailableListener", "\t\t------Exception "+ex);
                        }

                        //free lock
                        lock (_lock)
                            isBusy = false;
                    });
                }
            }
            mTextureView.UnlockCanvasAndPost(canvas);
        }

        //private FaceEyes Detect(byte [] imageBytes)
        private FaceEyes Detect(Mat image2)
        {
            FaceEyes FE = new FaceEyes();

            //if (face != null && eye != null)
            //{
            //watch = Stopwatch.StartNew();

            using (UMat ugray = new UMat())
            {
                CvInvoke.CvtColor(image2, ugray, Emgu.CV.CvEnum.ColorConversion.Bgr2Gray);

                //normalizes brightness and increases contrast of image
                CvInvoke.EqualizeHist(ugray, ugray);

                //Detect faces  from gray scale image and store locations as rectangle
                //The first dimensional is channel
                //The second dimension is index of rectangle in specific channel
                Rectangle[] facesDetected = face.DetectMultiScale(
                   ugray,
                   1.1,
                   10,
                   new System.Drawing.Size(20, 20));

                FE.Faces.AddRange(facesDetected);

                foreach (Rectangle f in facesDetected)
                {
                    Log.Error(TAG, "\t\t------Face DETECTED");

                    //Get region of interest on faces
                    using (UMat faceRegion = new UMat(ugray, f))
                    {
                        Rectangle[] eyesDetected = eye.DetectMultiScale(
                           faceRegion,
                           1.1,
                           10,
                           new System.Drawing.Size(20, 20));

                        foreach (Rectangle e in eyesDetected)
                        {
                            Log.Error(TAG, "\t\t------Eye DETECTED");

                            Rectangle eyeRect = e;
                            eyeRect.Offset(f.X, f.Y);
                            FE.Eyes.Add(eyeRect);
                        }
                    }
                }
                //}
                //watch.Stop();
                Log.Error(TAG, "\t\t------FaceEyes Detect\tDONE" );

            }

            return FE;
        }

        private static Android.Util.Size ChooseOptimalSize(Android.Util.Size[] choices, int textureViewWidth, int textureViewHeight,
            int maxWidth, int maxHeight, Android.Util.Size aspectRatio)
        {
            // Collect supported resolutions that are at least as big as preview Surface
            var bigEnough = new List<Android.Util.Size>();

            // Collect supported resolutions that are smaller than preview Surface
            var notBigEnough = new List<Android.Util.Size>();
            int w = aspectRatio.Width;
            int h = aspectRatio.Height;

            for (var i = 0; i < choices.Length; i++)
            {
                Android.Util.Size option = choices[i];
                //if ((option.Width <= maxWidth) && (option.Height <= maxHeight) && option.Height == option.Width * h / w)
                if ((option.Width <= maxWidth) && (option.Height <= maxHeight))
                {
                    if (option.Width >= textureViewWidth && option.Height >= textureViewHeight)
                        bigEnough.Add(option);
                    else
                        notBigEnough.Add(option);
                }
            }

            // Pick smallest of those big enough. If there is no one big enough, pick the
            // largest of those not big enough.
            if (bigEnough.Count > 0)
                return (Android.Util.Size)Collections.Min(bigEnough, new CompareSizesByArea());
            else if (notBigEnough.Count > 0)
                return (Android.Util.Size)Collections.Max(notBigEnough, new CompareSizesByArea());
            else
            {
                Log.Error(TAG, "\t\t-----Couldn't find any suitable preview size");
                return choices[0];
            }
        }

        // Sets up member variables related to camera.
        private void SetUpCameraOutputs(int width, int height)
        {
            var manager = (CameraManager)GetSystemService(Context.CameraService);
            try
            {
                for (var i = 0; i < manager.GetCameraIdList().Length; i++)
                {
                    var cameraId = manager.GetCameraIdList()[i];
                    CameraCharacteristics characteristics = manager.GetCameraCharacteristics(cameraId);

                    // don't use front facing camera in this sample.
                    var facing = (Integer)characteristics.Get(CameraCharacteristics.LensFacing);
                    if (facing != null && facing == (Integer.ValueOf((int)LensFacing.Front)))
                        continue;

                    var map = (StreamConfigurationMap)characteristics.Get(CameraCharacteristics.ScalerStreamConfigurationMap);
                    if (map == null)
                        continue;

                    // For still image captures, use largest available size.
                    Android.Util.Size largest = (Android.Util.Size)Collections.Max(Arrays.AsList(map.GetOutputSizes((int)ImageFormatType.Jpeg)),  
                        new CompareSizesByArea());
                    //mImageReader = ImageReader.NewInstance(largest.Width/8, largest.Height/8, ImageFormatType.Jpeg, 8);
                    mImageReader = ImageReader.NewInstance(1024, 768, ImageFormatType.Jpeg, 32);
                    mImageReader.SetOnImageAvailableListener(mOnImageAvailableListener, mBackgroundHandler);

                    Log.Error(TAG, "\t\t-----ImageReader.NewInstance:" + 1024 + "," + 768);

                    // Find out if needed to swap dimension to get preview size relative to sensor
                    // coordinate.
                    var displayRotation = WindowManager.DefaultDisplay.Rotation;
                    //noinspection ConstantConditions
                    mSensorOrientation = (int)characteristics.Get(CameraCharacteristics.SensorOrientation);
                    bool swappedDimensions = false;
                    switch (displayRotation)
                    {
                        case SurfaceOrientation.Rotation0:
                        case SurfaceOrientation.Rotation180:
                            if (mSensorOrientation == 90 || mSensorOrientation == 270)
                                swappedDimensions = true;
                            break;
                        case SurfaceOrientation.Rotation90:
                        case SurfaceOrientation.Rotation270:
                            if (mSensorOrientation == 0 || mSensorOrientation == 180)
                                swappedDimensions = true;
                            break;
                        default:
                            Log.Error(TAG, "\t\t-----Display rotation is invalid: " + displayRotation);
                            break;
                    }

                    var displaySize = new Android.Graphics.Point();
                    WindowManager.DefaultDisplay.GetSize(displaySize);
                    var rotatedPreviewWidth = width;
                    var rotatedPreviewHeight = height;
                    var maxPreviewWidth = displaySize.X;
                    var maxPreviewHeight = displaySize.Y;

                    if (swappedDimensions)
                    {
                        rotatedPreviewWidth = height;
                        rotatedPreviewHeight = width;
                        maxPreviewWidth = displaySize.Y;
                        maxPreviewHeight = displaySize.X;
                    }

                    if (maxPreviewWidth > MAX_PREVIEW_WIDTH)
                        maxPreviewWidth = MAX_PREVIEW_WIDTH;

                    if (maxPreviewHeight > MAX_PREVIEW_HEIGHT)
                        maxPreviewHeight = MAX_PREVIEW_HEIGHT;

                    // Danger, W.R.! Attempting to use too large preview size could  exceed camera
                    // bus' bandwidth limitation, resulting in gorgeous previews but storage of
                    // garbage capture data.
                    mPreviewSize = ChooseOptimalSize(map.GetOutputSizes(Class.FromType(typeof(SurfaceTexture))),
                        rotatedPreviewWidth, rotatedPreviewHeight, maxPreviewWidth, maxPreviewHeight, largest);

                    // fit aspect ratio of TextureView to size of preview picked.
                    var orientation = Resources.Configuration.Orientation;
                    if (orientation == Orientation.Landscape)
                        mTextureView.SetAspectRatio(mPreviewSize.Width/2, mPreviewSize.Height/2);
                    else
                        mTextureView.SetAspectRatio(mPreviewSize.Height/2, mPreviewSize.Width/2);

                    Log.Error(TAG, "\t\t -----mTextureView.SetAspectRatio:" + mPreviewSize.Width/2 + "," + mPreviewSize.Height/2);

                    // Check if flash is supported.
                    var available = (Boolean)characteristics.Get(CameraCharacteristics.FlashInfoAvailable);
                    if (available == null)
                        mFlashSupported = false;
                    else
                        mFlashSupported = (bool)available;

                    mCameraId = cameraId;
                    return;
                }
            }
            catch (CameraAccessException e)
            {
                e.PrintStackTrace();
            }
            catch (NullPointerException e)
            {
                // Currently thrown when Camera2API is used but not supported on the device this code runs.
                //ErrorDialog.NewInstance(GetString(Resource.String.camera_error)).Show(ChildFragmentManager, FRAGMENT_DIALOG);
            }
        }

        // Opens camera specified by {@link Camera2BasicFragment#mCameraId}.
        public void OpenCamera(int width, int height)
        {
            SetUpCameraOutputs(width, height);
            ConfigureTransform(width, height);
            var manager = (CameraManager)GetSystemService(Context.CameraService);
            try
            {
                if (!mCameraOpenCloseLock.TryAcquire(2500, TimeUnit.Microseconds))
                    throw new RuntimeException("Time out waiting to lock camera opening.");
                manager.OpenCamera(mCameraId, mStateCallback, mBackgroundHandler);
            }
            catch (CameraAccessException e)
            {
                e.PrintStackTrace();
            }
            catch (InterruptedException e)
            {
                throw new RuntimeException("Interrupted while trying to lock camera opening.", e);
            }
        }

        // Closes current {@link CameraDevice}.
        private void CloseCamera()
        {
            try
            {
                mCameraOpenCloseLock.Acquire();
                if (null != mCaptureSession)
                {
                    mCaptureSession.Close();
                    mCaptureSession = null;
                }
                if (null != mCameraDevice)
                {
                    mCameraDevice.Close();
                    mCameraDevice = null;
                }
                if (null != mImageReader)
                {
                    mImageReader.Close();
                    mImageReader = null;
                }
            }
            catch (InterruptedException e)
            {
                throw new RuntimeException("Interrupted while trying to lock camera closing.", e);
            }
            finally
            {
                mCameraOpenCloseLock.Release();
            }
        }

        // Starts background thread and its {@link Handler}.
        private void StartBackgroundThread()
        {
            mBackgroundThread = new HandlerThread("CameraBackground");
            mBackgroundThread.Start();
            mBackgroundHandler = new Handler(mBackgroundThread.Looper);
            Log.Error(TAG, "\t\t -----START BackgroundThread");

        }

        // Stops background thread and its {@link Handler}.
        private void StopBackgroundThread()
        {
            mBackgroundThread.QuitSafely();
            try
            {
                mBackgroundThread.Join();
                mBackgroundThread = null;
                mBackgroundHandler = null;
            }
            catch (InterruptedException e)
            {
                e.PrintStackTrace();
            }
            Log.Error(TAG, "\t\t -----STOP BackgroundThread");

        }

        // Creates new {@link CameraCaptureSession} for camera preview.
        public void CreateCameraPreviewSession()
        {
            try
            {
                SurfaceTexture texture = mTextureView.SurfaceTexture;
                if (texture == null)
                    throw new IllegalStateException("texture is null");

                // configure size of default buffer to be size of camera preview want.
                texture.SetDefaultBufferSize(mPreviewSize.Width, mPreviewSize.Height);

                // output Surface needed to start preview.
                Surface surface = new Surface(texture);

                // set up CaptureRequest.Builder with output Surface.
                mPreviewRequestBuilder = mCameraDevice.CreateCaptureRequest(CameraTemplate.Preview);
                mPreviewRequestBuilder.AddTarget(surface);
                mPreviewRequestBuilder.AddTarget(mImageReader.Surface);
                Log.Error(TAG, "\t\t -----set up CaptureRequest.Builder with output Surface");

                // create CameraCaptureSession for camera preview.
                List<Surface> surfaces = new List<Surface>();
                surfaces.Add(surface);
                surfaces.Add(mImageReader.Surface);
                mCameraDevice.CreateCaptureSession(surfaces, new CameraCaptureSessionCallback(this), null);
                Log.Error(TAG, "\t\t -----create CameraCaptureSession for camera preview");
            }
            catch (CameraAccessException e)
            {
                e.PrintStackTrace();
            }

            Log.Error(TAG, "\t\t -----CreateCameraPreviewSession DONE");
        }

        // WTF is this for?
        public static T Cast<T>(Java.Lang.Object obj) where T : class
        {
            var propertyInfo = obj.GetType().GetProperty("Instance");
            return propertyInfo == null ? null : propertyInfo.GetValue(obj, null) as T;
        }

        // Configures necessary {@link android.graphics.Matrix} transformation to `mTextureView`.
        // should be called after camera preview size is determined in setUpCameraOutputs and also size of `mTextureView` is fixed.
        public void ConfigureTransform(int viewWidth, int viewHeight)
        {
            if (null == mTextureView || null == mPreviewSize)
                return;
            Log.Error("ConfigureTransform:", viewWidth+","+viewHeight);

            var rotation = (int)WindowManager.DefaultDisplay.Rotation;
            Matrix matrix = new Matrix();
            RectF viewRect = new RectF(0, 0, viewWidth, viewHeight);
            RectF bufferRect = new RectF(0, 0, mPreviewSize.Height, mPreviewSize.Width);
            float centerX = viewRect.CenterX();
            float centerY = viewRect.CenterY();

            if ((int)SurfaceOrientation.Rotation90 == rotation || (int)SurfaceOrientation.Rotation270 == rotation)
            {
                bufferRect.Offset(centerX - bufferRect.CenterX(), centerY - bufferRect.CenterY());
                matrix.SetRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.Fill);
                float scale = Math.Max((float)viewHeight / mPreviewSize.Height, (float)viewWidth / mPreviewSize.Width);
                matrix.PostScale(scale, scale, centerX, centerY);
                matrix.PostRotate(90 * (rotation - 2), centerX, centerY);
            }
            else if ((int)SurfaceOrientation.Rotation180 == rotation)
                matrix.PostRotate(180, centerX, centerY);

            mTextureView.SetTransform(matrix);
        }

        // Initiate still image capture.
        private void TakePicture()
        {
            LockFocus();
        }

        // Lock focus as first step for still image capture.
        private void LockFocus()
        {
            try
            {
                // how to tell camera to lock focus.
                mPreviewRequestBuilder.Set(CaptureRequest.ControlAfTrigger, (int)ControlAFTrigger.Start);

                // Tell #mCaptureCallback to wait for lock.
                mState = STATE_WAITING_LOCK;
                mCaptureSession.Capture(mPreviewRequestBuilder.Build(), mCaptureCallback, mBackgroundHandler);
            }
            catch (CameraAccessException e)
            {
                e.PrintStackTrace();
            }
        }

        // Run precapture sequence for capturing still image. should be called when
        // get response in {@link #mCaptureCallback} from {@link #lockFocus()}.
        public void RunPrecaptureSequence()
        {
            try
            {
                // how to tell camera to trigger.
                mPreviewRequestBuilder.Set(CaptureRequest.ControlAePrecaptureTrigger, (int)ControlAEPrecaptureTrigger.Start);

                // Tell #mCaptureCallback to wait for precapture sequence to be set.
                mState = STATE_WAITING_PRECAPTURE;
                mCaptureSession.Capture(mPreviewRequestBuilder.Build(), mCaptureCallback, mBackgroundHandler);
            }
            catch (CameraAccessException e)
            {
                e.PrintStackTrace();
            }
        }

        /*public void CapturePreviewShot()
        {
            try
            {
                //final Activity activity = getActivity();
                if (null == mCameraDevice) return;


                // CaptureRequest.Builder that use to take picture.
                //final CaptureRequest.Builder captureBuilder = mCameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
                CaptureRequest.Builder captureBuilder = mCameraDevice.CreateCaptureRequest(CameraTemplate.Preview);
                captureBuilder.AddTarget(mImageReader.Surface);

                // Use same AE and AF modes as preview.
                captureBuilder.Set(CaptureRequest.ControlAfMode, (int)ControlAFMode.ContinuousPicture);
                //SetAutoFlash(captureBuilder);

                // Orientation
                int rotation = (int)WindowManager.DefaultDisplay.Rotation;
                captureBuilder.Set(CaptureRequest.JpegOrientation, GetOrientation(rotation));

                mCaptureSession.StopRepeating();
                //mCaptureSession.Capture(captureBuilder.Build(), new CameraCapturePreviewSessionCallback(this), null);
                mCaptureSession.Capture(captureBuilder.Build(), new CameraCapturePreviewSessionCallback(this), mBackgroundHandler);
            }
            catch (CameraAccessException e)
            {
                e.PrintStackTrace();
            }
        }*/

        // Capture still picture. should be called when get response in
        // {@link #mCaptureCallback} from both {@link #lockFocus()}.
        public void CaptureStillPicture()
        {
            try
            {
                if (null == mCameraDevice)
                    return;

                // CaptureRequest.Builder that use to take picture.
                CaptureRequest.Builder captureBuilder = mCameraDevice.CreateCaptureRequest(CameraTemplate.StillCapture);
                captureBuilder.AddTarget(mImageReader.Surface);

                // Use same AE and AF modes as preview.
                captureBuilder.Set(CaptureRequest.ControlAfMode, (int)ControlAFMode.ContinuousPicture);
                SetAutoFlash(captureBuilder);

                // Orientation
                int rotation = (int)WindowManager.DefaultDisplay.Rotation;
                captureBuilder.Set(CaptureRequest.JpegOrientation, GetOrientation(rotation));

                mCaptureSession.StopRepeating();
                mCaptureSession.Capture(captureBuilder.Build(), new CameraCaptureStillPictureSessionCallback(this), null);
            }
            catch (CameraAccessException e)
            {
                e.PrintStackTrace();
            }
        }

        // Retrieves JPEG orientation from specified screen rotation.
        private int GetOrientation(int rotation)
        {
            // Sensor orientation is 90 for most devices, or 270 for some devices (eg. Nexus 5X)
            // have to take that into account and rotate JPEG properly.
            // For devices with orientation of 90, simply return our mapping from ORIENTATIONS.
            // For devices with orientation of 270, needed to rotate JPEG 180 degrees.
            return (ORIENTATIONS.Get(rotation) + mSensorOrientation + 270) % 360;
        }

        // Unlock focus. should be called when still image capture sequence is finished.
        public void UnlockFocus()
        {
            try
            {
                // Reset auto-focus trigger
                mPreviewRequestBuilder.Set(CaptureRequest.ControlAfTrigger, (int)ControlAFTrigger.Cancel);
                SetAutoFlash(mPreviewRequestBuilder);
                mCaptureSession.Capture(mPreviewRequestBuilder.Build(), mCaptureCallback, mBackgroundHandler);

                // After this, camera will go back to normal state of preview.
                mState = STATE_PREVIEW;
                mCaptureSession.SetRepeatingRequest(mPreviewRequest, mCaptureCallback, mBackgroundHandler);
            }
            catch (CameraAccessException e)
            {
                e.PrintStackTrace();
            }
        }

        //this is only if View.IOnClickListener is implemented
        //public void OnClick(View v)
        //{
        //   switch (v.Id)
        //   {
        //       case Resource.Id.picture:
        //           TakePicture();
        //           break;
        //       case Resource.Id.info:
        //           EventHandler<DialogClickEventArgs> nullHandler = null;
        //           Activity activity = Activity;
        //           if (activity != null)
        //           {
        //               new AlertDialog.Builder(activity)
        //                   .SetMessage("This sample demonstrates basic use of Camera2 API. ...")
        //                   .SetPositiveButton(Android.Resource.String.Ok, nullHandler)
        //                   .Show();
        //           }
        //           break;
        //   }
        //}

        public void SetAutoFlash(CaptureRequest.Builder requestBuilder)
        {
            if (mFlashSupported)
                requestBuilder.Set(CaptureRequest.ControlAeMode, (int)ControlAEMode.OnAutoFlash);
        }

        private class FaceEyes
        {
            public List<Rectangle> Faces { get; set; } = new List<Rectangle>();
            public List<Rectangle> Eyes { get; set; } = new List<Rectangle>();

            public int Count
            {
                get
                {
                    return Faces.Count + Eyes.Count;
                }
            }
        }
    }
}